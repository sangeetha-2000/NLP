{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYffZdXHmHjd"
   },
   "source": [
    "<table align=\"left\" width=100%>\n",
    "    <tr>\n",
    "        <td width=\"20%\">\n",
    "            <img src=\"faculty.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"center\">\n",
    "                <font color=\"#21618C\" size=8px>\n",
    "                  <b> Assignment Questions </b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NisFmsKamHjp"
   },
   "source": [
    "Total Marks:  30 Marks\n",
    "\n",
    "\n",
    "### About the data set (COMPANY_Reviews)\n",
    "\n",
    "The dataset contains Text reviews. The aim of this assignment is to classsify the review texts into two categories. \n",
    "\n",
    "Attribute information: \n",
    " \n",
    "Dataset has two columns:\n",
    "Column2: Review Text\n",
    "Column1: Two Classes. Positive and negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfwprmJMmHjr"
   },
   "source": [
    "## Table of Content\n",
    "\n",
    "1. **[Import Libraries](#lib)**\n",
    "2. **[Load the Data  (5 Marks)](#prep)**\n",
    "    - 2.1 - **[Read the Data   (1 Mark)](#read)**\n",
    "    - 2.2 - **[Dispay the first ten rows (1 Mark) ](#dtype)**\n",
    "    - 2.3 - **[Display the information about the data (1 Mark)](#drop)**\n",
    "    - 2.4 - **[Encode the sentiment column values as 1 or 0 (2 Marks)](#dummy)**\n",
    "3.  **[Data preprocessing  (7 Marks)](#prep)**\n",
    "    - 3.1 - **[Remove special characters and html tags (2 Marks)](#read)**\n",
    "    - 3.2 - **[Convert reviews into lowercase (1 Mark)](#dtype)**\n",
    "    - 3.3 - **[Removal of stop words (2 Marks)](#drop)**\n",
    "    - 3.4 - **[Apply stemming (2 Marks)](#dummy)**\n",
    "4.**[Convert review text into feature vector and classification (18 Marks)](#prep)**\n",
    "    - 4.1 - **[create BOW model (2 Marks)](#cut_off)**\n",
    "    - 4.2 - **[Training data and Test data -split  (1 Mark)](#dtype)**\n",
    "    - 4.3 - **[Define the Classification model (any one like NB, SVM or Random forest) train the model  (3 Marks) ](#drop)**\n",
    "    - 4.4 - **[Classification metrics analysis (2 Marks)](#dummy)**\n",
    "    - 4.5 - **[predict the class for your own review (2 Marks)](#dummy)**\n",
    "\n",
    "    - 4.6 - **[create feature vector using tf-idf  (2 Marks)](#cut_off)**\n",
    "    - 4.7 - **[Define the Classification model (any one like NB, SVM or Random forest) train the model (2 Marks)](#drop)**\n",
    "    - 4.8 - **[Classification metrics analysis (2 Marks)](#dummy)**\n",
    "    - 4.9 - **[predict the class for your own review (2 Marks) ](#dummy)**\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wV8M-lomHjs"
   },
   "source": [
    "<a id=\"lib\"></a>\n",
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HF5D3CqhmHjs"
   },
   "source": [
    "**Let us import the required libraries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "7Y2AHmx-mHjt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Cbu-UrzzpJg"
   },
   "source": [
    "2. Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6-Vk7n6z8X-"
   },
   "source": [
    "2.1 Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "mpmjR7BGzvIe"
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"sentiment_analysis.csv\",encoding=\" ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9c77n7WMz_o9"
   },
   "source": [
    "2.2 Dispay the first ten rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "6ikzUby10TaB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>positive</td>\n",
       "      <td>In the third quarter of 2010 , net sales incre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>positive</td>\n",
       "      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>positive</td>\n",
       "      <td>TeliaSonera TLSN said the offer is in line wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>positive</td>\n",
       "      <td>STORA ENSO , NORSKE SKOG , M-REAL , UPM-KYMMEN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                             Review\n",
       "0  negative  The international electronic industry company ...\n",
       "1  positive  With the new production plant the company woul...\n",
       "2  positive  According to the company 's updated strategy f...\n",
       "3  positive  FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...\n",
       "4  positive  For the last quarter of 2010 , Componenta 's n...\n",
       "5  positive  In the third quarter of 2010 , net sales incre...\n",
       "6  positive  Operating profit rose to EUR 13.1 mn from EUR ...\n",
       "7  positive  Operating profit totalled EUR 21.1 mn , up fro...\n",
       "8  positive  TeliaSonera TLSN said the offer is in line wit...\n",
       "9  positive  STORA ENSO , NORSKE SKOG , M-REAL , UPM-KYMMEN..."
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwlaQfbA0FtG"
   },
   "source": [
    "2.3 Display the information about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "as7IjoItz1Px"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1967 entries, 0 to 1966\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Sentiment  1967 non-null   object\n",
      " 1   Review     1967 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 30.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lw4qNA-p0JfW"
   },
   "source": [
    "2.4   Encode the sentiment column values as 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "9dYvIFp6z1gW"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>negative</td>\n",
       "      <td>HELSINKI Thomson Financial - Shares in Cargote...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>negative</td>\n",
       "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>negative</td>\n",
       "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>negative</td>\n",
       "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>negative</td>\n",
       "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1967 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentiment                                             Review  \\\n",
       "0     negative  The international electronic industry company ...   \n",
       "1     positive  With the new production plant the company woul...   \n",
       "2     positive  According to the company 's updated strategy f...   \n",
       "3     positive  FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...   \n",
       "4     positive  For the last quarter of 2010 , Componenta 's n...   \n",
       "...        ...                                                ...   \n",
       "1962  negative  HELSINKI Thomson Financial - Shares in Cargote...   \n",
       "1963  negative  LONDON MarketWatch -- Share prices ended lower...   \n",
       "1964  negative  Operating profit fell to EUR 35.4 mn from EUR ...   \n",
       "1965  negative  Net sales of the Paper segment decreased to EU...   \n",
       "1966  negative  Sales in Finland decreased by 10.5 % in Januar...   \n",
       "\n",
       "      Sentiment_enc  \n",
       "0                 0  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "...             ...  \n",
       "1962              0  \n",
       "1963              0  \n",
       "1964              0  \n",
       "1965              0  \n",
       "1966              0  \n",
       "\n",
       "[1967 rows x 3 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl= LabelEncoder()\n",
    "df['Sentiment_enc']=lbl.fit_transform(df['Sentiment'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riUOzf5-0rvK"
   },
   "source": [
    "3.  Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwWFwlWe0u30"
   },
   "source": [
    "3.1 Remove special characters and html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub('<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    return text\n",
    "\n",
    "df['Review'] = df['Review'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q77N0hdq01i3"
   },
   "source": [
    "3.2 - Convert reviews into lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "GQS9y4zF0m7d"
   },
   "outputs": [],
   "source": [
    "df['Review'] = df['Review'].str.lower()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4yqhrRo06vs"
   },
   "source": [
    "3.3 - Removal of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ROYAL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['Review'] = df['Review'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nBGJIM50_jy"
   },
   "source": [
    "3.4 - Apply stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "5B368srR1C_y"
   },
   "outputs": [],
   "source": [
    "\n",
    "stemmer = PorterStemmer()\n",
    "df['Review'] = df['Review'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "Z0nOjVZTz1rv"
   },
   "source": [
    "All the preprocessing done in a single loop\n",
    "corpus=[]\n",
    "for i in range(0, 1967):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df['Review'][i])\n",
    "    review=review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGrTE65k1DrN"
   },
   "source": [
    "4.  Convert review text into feature vector and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrPSrWZH1Wlk"
   },
   "source": [
    "4.1 - create BOW model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "0-j-jbt51aFL"
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(df['Review']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQoRL8FO1auR"
   },
   "source": [
    "4.2 - Training data and Test data -split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "EBCsPsUr1eD8"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hEad1Qn1epR"
   },
   "source": [
    "4.3 - Define the Classification model (any one like NB, SVM or Random forest) train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "MDskreiZ1jqb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUDSEr6I1kCh"
   },
   "source": [
    "4.4  Classification metrics analysis and plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "TculUM1w1qnY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[131  50]\n",
      " [133 277]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6903553299492385"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fG118sNZ1tWW"
   },
   "source": [
    "4.5 - predict the class for your own review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "KhP3I7BtAg6j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "new_review = 'The company laidoff the employee'\n",
    "new_review = re.sub('[^a-zA-Z]', ' ', new_review)\n",
    "new_review = new_review.lower()\n",
    "new_review = new_review.split()\n",
    "ps = PorterStemmer()\n",
    "all_stopwords = stopwords.words('english')\n",
    "all_stopwords.remove('not')\n",
    "new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]\n",
    "new_review = ' '.join(new_review)\n",
    "new_corpus = [new_review]\n",
    "new_X_test = cv.transform(new_corpus).toarray()\n",
    "new_y_pred = classifier.predict(new_X_test)\n",
    "print(new_y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgo2bgfUAnHz"
   },
   "source": [
    "4.6 - create feature vector using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "mAGiKUBrAob7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROYAL\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaland</th>\n",
       "      <th>aalborg</th>\n",
       "      <th>ab</th>\n",
       "      <th>abb</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abn</th>\n",
       "      <th>abp</th>\n",
       "      <th>abroad</th>\n",
       "      <th>ac</th>\n",
       "      <th>...</th>\n",
       "      <th>yy</th>\n",
       "      <th>zahariev</th>\n",
       "      <th>zaharova</th>\n",
       "      <th>zero</th>\n",
       "      <th>zgodi</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zinclead</th>\n",
       "      <th>zoltan</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1967 rows × 3888 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aaland  aalborg   ab  abb  abil  abl  abn  abp  abroad   ac  ...   yy  \\\n",
       "0        0.0      0.0  0.0  0.0   0.0  0.0  0.0  0.0     0.0  0.0  ...  0.0   \n",
       "1        0.0      0.0  0.0  0.0   0.0  0.0  0.0  0.0     0.0  0.0  ...  0.0   \n",
       "2        0.0      0.0  0.0  0.0   0.0  0.0  0.0  0.0     0.0  0.0  ...  0.0   \n",
       "3        0.0      0.0  0.0  0.0   0.0  0.0  0.0  0.0     0.0  0.0  ...  0.0   \n",
       "4        0.0      0.0  0.0  0.0   0.0  0.0  0.0  0.0     0.0  0.0  ...  0.0   \n",
       "...      ...      ...  ...  ...   ...  ...  ...  ...     ...  ...  ...  ...   \n",
       "1962     0.0      0.0  0.0  0.0   0.0  0.0  0.0  0.0     0.0  0.0  ...  0.0   \n",
       "1963     0.0      0.0  0.0  0.0   0.0  0.0  0.0  0.0     0.0  0.0  ...  0.0   \n",
       "1964     0.0      0.0  0.0  0.0   0.0  0.0  0.0  0.0     0.0  0.0  ...  0.0   \n",
       "1965     0.0      0.0  0.0  0.0   0.0  0.0  0.0  0.0     0.0  0.0  ...  0.0   \n",
       "1966     0.0      0.0  0.0  0.0   0.0  0.0  0.0  0.0     0.0  0.0  ...  0.0   \n",
       "\n",
       "      zahariev  zaharova  zero  zgodi  zinc  zinclead  zoltan  zone  zoo  \n",
       "0          0.0       0.0  0.00    0.0   0.0       0.0     0.0   0.0  0.0  \n",
       "1          0.0       0.0  0.00    0.0   0.0       0.0     0.0   0.0  0.0  \n",
       "2          0.0       0.0  0.00    0.0   0.0       0.0     0.0   0.0  0.0  \n",
       "3          0.0       0.0  0.00    0.0   0.0       0.0     0.0   0.0  0.0  \n",
       "4          0.0       0.0  0.33    0.0   0.0       0.0     0.0   0.0  0.0  \n",
       "...        ...       ...   ...    ...   ...       ...     ...   ...  ...  \n",
       "1962       0.0       0.0  0.00    0.0   0.0       0.0     0.0   0.0  0.0  \n",
       "1963       0.0       0.0  0.00    0.0   0.0       0.0     0.0   0.0  0.0  \n",
       "1964       0.0       0.0  0.00    0.0   0.0       0.0     0.0   0.0  0.0  \n",
       "1965       0.0       0.0  0.00    0.0   0.0       0.0     0.0   0.0  0.0  \n",
       "1966       0.0       0.0  0.00    0.0   0.0       0.0     0.0   0.0  0.0  \n",
       "\n",
       "[1967 rows x 3888 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
    "tv_matrix = tv.fit_transform(df['Review'])\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "vocab = tv.get_feature_names()\n",
    "pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTl7KxmzApGy"
   },
   "source": [
    "4.7 Define the Classification model (any one like NB, SVM or Random forest) train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "Lf-_cY13AtXt"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71       181\n",
      "           1       0.85      0.93      0.89       410\n",
      "\n",
      "    accuracy                           0.84       591\n",
      "   macro avg       0.82      0.78      0.80       591\n",
      "weighted avg       0.84      0.84      0.83       591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest model with n_estimators=30\n",
    "random_forest = RandomForestClassifier(n_estimators=30)\n",
    "\n",
    "# Fit the model on the training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21o3UFWuAxCU"
   },
   "source": [
    "4.8 - Classification metrics analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "P1g_cW8-A4jS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71       181\n",
      "           1       0.85      0.93      0.89       410\n",
      "\n",
      "    accuracy                           0.84       591\n",
      "   macro avg       0.82      0.78      0.80       591\n",
      "weighted avg       0.84      0.84      0.83       591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_4qT-lVA42c"
   },
   "source": [
    "4.9 - predict the class for your own review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "OcCXMXZhA5g6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "new_review = 'The company laidoff the employee'\n",
    "new_review = re.sub('[^a-zA-Z]', ' ', new_review)\n",
    "new_review = new_review.lower()\n",
    "new_review = new_review.split()\n",
    "ps = PorterStemmer()\n",
    "all_stopwords = stopwords.words('english')\n",
    "all_stopwords.remove('not')\n",
    "new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]\n",
    "new_review = ' '.join(new_review)\n",
    "new_corpus = [new_review]\n",
    "new_X_test = cv.transform(new_corpus).toarray()\n",
    "new_y_pred = classifier.predict(new_X_test)\n",
    "print(new_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "new_review1 = 'The company increased the production'\n",
    "new_review1 = re.sub('[^a-zA-Z]', ' ', new_review1)\n",
    "new_review1 = new_review1.lower()\n",
    "new_review1 = new_review1.split()\n",
    "ps = PorterStemmer()\n",
    "all_stopwords = stopwords.words('english')\n",
    "all_stopwords.remove('not')\n",
    "new_review1 = [ps.stem(word) for word in new_review1 if not word in set(all_stopwords)]\n",
    "new_review1 = ' '.join(new_review1)\n",
    "new_corpus1 = [new_review1]\n",
    "new_X_test1 = cv.transform(new_corpus1).toarray()\n",
    "new_y_pred1 = random_forest.predict(new_X_test1)\n",
    "print(new_y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "18UWBv3Br72jn1pN9dlQaz4_uWpYg4oSj",
     "timestamp": 1679132470482
    },
    {
     "file_id": "11Whz9PBMyIm6ScAK1sUAuKZhlSwOIoIK",
     "timestamp": 1665466111274
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
